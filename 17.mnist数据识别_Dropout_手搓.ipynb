{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn,optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torchvision import datasets, transforms # 也是torch的工具，里面封装了更高级的功能\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集\n",
    "train_dataset = datasets.MNIST(root='./', # 这里选择当前路径下载，意思就是说可以在当前路径MINST文件夹内找到数据，数据是封装好了的\n",
    "                            train = True, # 下载训练集\n",
    "                            transform = transforms.ToTensor(), #把数据变成基本的数据类型tensor\n",
    "                            download = True) # 直接从封装好接口上载入\n",
    "\n",
    "# 测试集\n",
    "test_dataset = datasets.MNIST(root='./', # 这里选择当前路径下载\n",
    "                            train = False, # 下载训练集\n",
    "                            transform = transforms.ToTensor(), #把数据变成基本的数据类型tensor\n",
    "                            download = True) # 直接从封装好接口上载入\n",
    "\n",
    "train_dataset # 这个东西已经被封装成了60000个点，使用Data_loader拿出来用就好\n",
    "len(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2599d405040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 批次大小，每次训练选择多少的数据\n",
    "batch_size = 64 \n",
    "\n",
    "# 装载训练集\n",
    "# dataloader相当于创建了一个数据生成器\n",
    "# 在这个里面数据就已经封装好了（train_loader和test_loader里面）\n",
    "train_loader = DataLoader(dataset = train_dataset,  # 数据的来源\n",
    "                          batch_size = batch_size,  # 批次的大小\n",
    "                          shuffle = True) # 数据是否进行打乱\n",
    "\n",
    "test_loader = DataLoader(dataset = test_dataset, # 来源于测试集\n",
    "                         batch_size = batch_size,\n",
    "                         shuffle = True)\n",
    "\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n",
      "tensor([0, 8, 4, 6, 9, 4, 4, 6, 9, 9, 9, 1, 8, 3, 3, 0, 6, 6, 9, 7, 3, 9, 5, 3,\n",
      "        5, 0, 7, 2, 9, 2, 7, 8, 6, 1, 6, 3, 0, 3, 9, 7, 1, 9, 4, 4, 3, 9, 8, 7,\n",
      "        3, 4, 1, 2, 9, 7, 2, 1, 2, 1, 1, 1, 1, 4, 7, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据生成器使用方法——在循环中进行使用\n",
    "for i,data in enumerate(train_loader): #enumerate是为了每一批次的数据增加一个索引i\n",
    "    inputs, labels = data # data里面包含了要输入的量和输出的标签值\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    break\n",
    "print(labels)\n",
    "# 64个样本 1个通道（黑白） 28*28的像素\n",
    "# 标签同样是64个，标签值代表了是哪个数据\n",
    "len(train_loader) # 938*64 = 60032 刚好枚举完"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对以下网络的一些解释\n",
    "定义在网络结构里面的每一个背后都内含参数的\n",
    "全连接层会对不同的样本进行分别处理\n",
    "但是softmax是可以跨样本进行处理的（可能为了后续一些算法？）\n",
    "如果dim=0，则会对每一列进行归一化，不符合我们要求，所以要dim=1，完成行归一化\n",
    "\n",
    "# Dropout的相应用法\n",
    "Dropout一般在隐藏层中使用，编写代码的时候写在网络结构层编写\n",
    "在写网络结构时，可以使用封装代码\n",
    "非封装：self.fc1 = nn.Linear(784,500)\n",
    "封装版：self.layer1 = nn.Sequential(nn.Linear(784,500), nn.Dropout(p=0.5), nn.Tanh())\n",
    "然后调用的时候直接用layer1即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义网络结构 Pytorch，一个网络结构（初始化） 一个网络计算（得到结果）\n",
    "# 如果要用 Dropout，就要使用多层的网络结构\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # 是方法函数就需要用()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(784,500), nn.Dropout(p=0.5), nn.Tanh())\n",
    "        self.layer2 = nn.Sequential(nn.Linear(500,300), nn.Dropout(p=0.5), nn.Tanh()) # 隐藏层是超参数\n",
    "        self.layer3 = nn.Sequential(nn.Linear(300,10), nn.Softmax(dim=1)) # 输出层不用Dropout，这些nn的方法第一个字母大写\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 输入的时候维度是[64,1,28,28], 全连接层只能处理2维数据，第一个维度是样本索引，第二个维度是样本内的\n",
    "        # ([64, 1, 28, 28])->(64, 784)\n",
    "        x = x.reshape(x.size()[0],-1) #-1代表自适应，变成64行，784列\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义模型（对象化）\n",
    "model = Net() #对象化也是一个方法\n",
    "# 定义代价函数\n",
    "# 这是一个类，你需要实例化这个类！\n",
    "mse_loss = nn.CrossEntropyLoss() #交叉熵损失\n",
    "# 定义优化器\n",
    "# 要传入模型参数和学习率\n",
    "LR = 0.5\n",
    "optimizer = optim.SGD(model.parameters(), LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 进行模型的训练和测试方法——一边训练一边测试模型效果\n",
    "def train():\n",
    "    # 在dropout里面需要额外加上model.train()\n",
    "    model.train() # 代表是训练状态，此时模型的dropout是起作用的\n",
    "    for i,data in enumerate(train_loader): # 对迭代器进行分析\n",
    "        # 循环一次，就会获得一次数据的批次和标签，这很重要！\n",
    "        inputs, labels = data\n",
    "        # 获得模型预测结果, 这个结果是[64, 10]的一个矩阵，64是批次，10是概率值\n",
    "        out = model(inputs)\n",
    "        \n",
    "        # 用交叉熵损失，用交叉损失时，函数会内部自动转换成独热编码\n",
    "        # 其中，out是（64，10）数组，labels是64的一位数组\n",
    "        # 根据这个函数的用法，两者不需要对齐，只要保证第一个数都是minibatch值即可\n",
    "        loss = mse_loss(out, labels)\n",
    "        \n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 计算梯度\n",
    "        loss.backward()\n",
    "        # 修改权值\n",
    "        optimizer.step()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    # 测试集准确率\n",
    "    correct = 0\n",
    "    for i,data in enumerate(test_loader): # 每一次都是在对一个训练好的模型进行评估，把所有的测试集跑了一边\n",
    "        inputs, labels = data\n",
    "        out = model(inputs)\n",
    "        # torch.max计算完后得到两个值，获得最大值和最大值所在的位置，dim=1代表对每一行进行操作\n",
    "        # 这里会对64行每一行都进行操作的\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        # 正确个数\n",
    "        correct += (predicted == labels).sum() # 这里面的true和false会一个一个对比\n",
    "    print('Test acc:{0}'.format(correct.item()/len(test_dataset)))\n",
    "\n",
    "    # 训练集准确率\n",
    "    correct = 0\n",
    "    for i,data in enumerate(train_loader): # 每一次都是在对一个训练好的模型进行评估，把所有的测试集跑了一边\n",
    "        inputs, labels = data\n",
    "        out = model(inputs)\n",
    "        # torch.max计算完后得到两个值，获得最大值和最大值所在的位置，dim=1代表对每一行进行操作\n",
    "        # 这里会对64行每一行都进行操作的\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        # 正确个数\n",
    "        correct += (predicted == labels).sum() # 这里面的true和false会一个一个对比\n",
    "    print('Train acc:{0}'.format(correct.item()/len(train_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout 使用场景\n",
    "并不一定让准确度变高，在模型比较复杂的情况下，应当使用，防止过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Test acc:0.9174\n",
      "Train acc:0.9161833333333333\n",
      "epoch: 1\n",
      "Test acc:0.923\n",
      "Train acc:0.9253666666666667\n",
      "epoch: 2\n",
      "Test acc:0.9392\n",
      "Train acc:0.94135\n",
      "epoch: 3\n",
      "Test acc:0.9449\n",
      "Train acc:0.9462333333333334\n",
      "epoch: 4\n",
      "Test acc:0.9463\n",
      "Train acc:0.9490833333333333\n",
      "epoch: 5\n",
      "Test acc:0.9472\n",
      "Train acc:0.95165\n",
      "epoch: 6\n",
      "Test acc:0.9536\n",
      "Train acc:0.9582666666666667\n",
      "epoch: 7\n",
      "Test acc:0.9566\n",
      "Train acc:0.962\n",
      "epoch: 8\n",
      "Test acc:0.9563\n",
      "Train acc:0.9627333333333333\n",
      "epoch: 9\n",
      "Test acc:0.9572\n",
      "Train acc:0.9638833333333333\n",
      "epoch: 10\n",
      "Test acc:0.9618\n",
      "Train acc:0.9663166666666667\n",
      "epoch: 11\n",
      "Test acc:0.962\n",
      "Train acc:0.9673333333333334\n",
      "epoch: 12\n",
      "Test acc:0.9637\n",
      "Train acc:0.9698166666666667\n",
      "epoch: 13\n",
      "Test acc:0.9609\n",
      "Train acc:0.96905\n",
      "epoch: 14\n",
      "Test acc:0.9642\n",
      "Train acc:0.9717333333333333\n",
      "epoch: 15\n",
      "Test acc:0.9638\n",
      "Train acc:0.9713666666666667\n",
      "epoch: 16\n",
      "Test acc:0.9641\n",
      "Train acc:0.9714333333333334\n",
      "epoch: 17\n",
      "Test acc:0.9656\n",
      "Train acc:0.9737\n",
      "epoch: 18\n",
      "Test acc:0.9644\n",
      "Train acc:0.9733166666666667\n",
      "epoch: 19\n",
      "Test acc:0.9675\n",
      "Train acc:0.9756333333333334\n"
     ]
    }
   ],
   "source": [
    "# 循环运行\n",
    "# 获得了更快的收敛速度\n",
    "for epoch in range(20):\n",
    "    print('epoch:', epoch)\n",
    "    train()\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这里是一个常见的框架\n",
    "数据集的载入\n",
    "定义批次大小和分割数据集（接下去在循环中对这个数据进行训练）\n",
    "定义网络结构 和 网络运算 def __init__(self) 和 def forward(self, x)\n",
    "对象化模型 代价函数 优化器\n",
    "写网络如何训练测试——用两个模块封装好\n",
    "训练：输出结果 求损失 梯度归零 更新参数\n",
    "测试：输出结果\n",
    "\n",
    "一个大循环"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "{AI_Training_Test}",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
